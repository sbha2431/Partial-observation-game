The ideal choice of an abstraction partition is the one that balances precision and computational burden. More precisely, the abstraction should be precise enough for the agent to satisfy its surveillance objective. On the other hand, an abstraction that is too precise, often results in an intractably large state space of the resulting game. Thus, a good abstraction is one that gives the right level of precision where it is needed, and is coarse (that is, generates fewer abstract belief states) where precision is not needed. Thus, choosing a good abstraction partition is often specific to the game environment and the surveillance specification. In section \ref{sec:experiments}, we present  examples with user specified partitions resulting in feasible  abstract games.

In the previous section, we discussed that a winning strategy for the agent in the abstract belief game corresponds to a strategy for the agent in the concrete belief game. This, fact does not hold in general for the abstract winning strategies of the target. We refer to the abstract winning  strategies for the target as \emph{abstract counterexamples}.

Given an abstract counterexample, there are two possibilities: it can either be a counterexample in the concrete belief game, meaning that the agent cannot satisfy the surveillance objective, or it may exist due to the coarseness of the abstraction partition. We now discuss in more detail counterexamples in safety and liveness surveillance games. The latter generalizes also to general surveillance objectives.
